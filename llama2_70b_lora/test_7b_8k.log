[2024-02-28 20:42:25,648] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:9AX4dFSSpcAMAJhyYK5BBAhA6FO0voQ4qjlON/fIicA failed
[2024-02-28 20:42:27,064] [INFO] [runner.py:463:main] Using IP address of 172.16.1.34 for node compute34
[2024-02-28 20:42:27,065] [INFO] [runner.py:568:main] cmd = mpirun -n 8 -ppn 8 -hostfile hostfile_mpich -genv PYTHONSTARTUP=/etc/pythonstart -genv PYTHONPATH=/home/maliangl/ft/reference/llama2_70b_lora -genv MASTER_ADDR 172.16.1.34 -genv MASTER_PORT 29500 -genv WORLD_SIZE 8 -genv LOCAL_SIZE 8 -hosts compute34 /home/maliangl/miniconda3/envs/ft/bin/python -u /home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/launcher/launcher_helper.py --launcher mpich scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
My guessed rank = 2
My guessed rank = 0
My guessed rank = 1
My guessed rank = 3
My guessed rank = 6
My guessed rank = 7
My guessed rank = 4
My guessed rank = 5
[2024-02-28 20:42:31,556] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,561] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,563] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,565] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,565] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,566] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,567] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,570] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:31,820] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,824] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,824] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,828] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,828] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,828] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,828] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:42:31,828] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-7b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
My guessed rank = 4
My guessed rank = 7
My guessed rank = 5
My guessed rank = 6
My guessed rank = 0
My guessed rank = 1
My guessed rank = 2
My guessed rank = 3
[2024-02-28 20:42:36,988] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,106] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,106] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,109] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,114] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,117] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,118] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,121] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:42:37,314] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,314] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,799] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,799] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,799] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl
[2024-02-28 20:42:37,799] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,799] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,814] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,814] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,814] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,814] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,815] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,815] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,820] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,820] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:37,832] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:42:37,832] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:42:40,602] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 291, num_elems = 6.74B
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.67s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.23s/it]
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:33, 32.06 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:35, 31.92 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:34, 32.01 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:37, 31.80 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:21, 76.82 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 77.17 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:36, 31.87 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 76.91 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:39, 31.68 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:40, 31.63 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:24, 75.59 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:41, 31.58 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:02, 118.14 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:46, 135.39 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:15, 177.78 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:47, 263.15 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:01, 219.04 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:48, 133.08 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:37, 335.82 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:49, 132.25 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:48, 132.75 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:02, 215.13 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:02, 215.73 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:04, 116.23 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:01, 217.09 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:04, 116.33 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:04, 115.76 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:33<00:38, 327.32 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:37, 331.58 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:16, 175.13 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:16, 174.99 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:32, 354.02 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:26, 440.37 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:25, 446.67 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:27, 412.91 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:22, 474.51 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:25, 443.13 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:35, 325.98 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:35, 325.77 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:17, 599.91 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:40, 280.59 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:17, 603.79 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:19, 536.04 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:17, 614.90 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:24, 425.55 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:29, 356.68 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:24, 419.13 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:18, 510.61 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:15, 614.67 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:16, 580.25 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:23, 397.64 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:17, 547.05 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:15, 592.45 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:20, 455.68 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:36<00:21, 442.22 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:16, 580.25 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:15, 614.67 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:15, 592.45 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:17, 547.05 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:20, 455.68 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:18, 510.61 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:21, 442.22 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:51<00:23, 397.64 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:20, 105.02 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:49, 150.32 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:19, 105.83 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:15, 112.68 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:47, 156.61 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:20, 105.47 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:21, 104.35 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:49, 150.58 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:16, 109.89 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:14, 112.81 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:17, 109.57 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:48, 152.91 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:51, 145.42 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:03<00:33, 193.37 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:32, 196.92 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:35, 182.37 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 195.22 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 190.38 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:35, 181.25 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:34, 189.19 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:36, 177.36 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:24, 225.02 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:23, 233.14 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:08, 408.10 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:23, 233.14 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:23, 230.58 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:26, 209.30 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:13, 328.08 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:08, 418.24 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:23, 228.67 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:13, 321.46 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:25, 210.01 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:15, 280.29 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:14, 316.06 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:15, 279.55 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 503.19 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:25, 210.91 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:07, 432.85 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 523.50 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:15, 278.87 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:07, 436.47 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:03, 529.77 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:09, 366.47 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 610.60 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:09, 364.95 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 546.98 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:09, 370.51 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 576.23 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:08<00:04, 493.23 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:03, 578.19 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:08<00:05, 484.70 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:04, 521.33 examples/s]Map (num_proc=8):  87%|████████▋ | 15182/17457 [01:08<00:04, 484.26 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:04, 503.81 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:03, 546.09 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 598.09 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:04, 458.12 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 614.59 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 677.61 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 590.26 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 587.98 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 623.33 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 562.36 examples/s]Map (num_proc=8):  95%|█████████▍| 16547/17457 [01:10<00:01, 553.32 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:02, 517.54 examples/s]Map (num_proc=8):  95%|█████████▍| 16547/17457 [01:10<00:01, 527.06 examples/s]Map (num_proc=8):  95%|█████████▍| 16547/17457 [01:11<00:02, 442.86 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 326.80 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 316.17 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 376.72 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 310.61 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 368.69 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 343.19 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 315.18 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 323.81 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:01, 371.40 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:13<00:01, 334.80 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 426.25 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 347.89 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 354.62 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 383.81 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:13<00:01, 362.40 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 389.92 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:14<00:00, 384.39 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 407.10 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:14<00:01, 363.51 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 324.83 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:14<00:00, 380.42 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 404.57 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:14<00:00, 367.27 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 408.78 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 426.26 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:14<00:00, 371.80 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 395.70 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 232.59 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 362.15 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 365.68 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 297.30 examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 317.19 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 230.99 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 370.33 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 231.06 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 302.18 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 229.94 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 230.18 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 230.33 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 335.70 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 229.76 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 228.84 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.18 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.23 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.45 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.30 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.93 examples/s]
Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.14 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.65 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.20 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.18 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.09 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.21 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.53 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.62 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.70 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.74 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.71 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.83 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.96 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.96 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.98 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 36.69 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 36.87 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.40 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.47 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:57, 284.78 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:09, 1442.68 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3331.17 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 304.63 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1952.46 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3433.62 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 304.91 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 303.20 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1537.04 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1944.08 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:55, 298.33 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:03<00:03, 3073.20 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 299.45 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1512.04 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3387.62 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3604.66 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1894.69 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3384.42 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 307.38 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:04, 2389.83 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 302.61 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:04, 2341.75 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1531.55 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2078.52 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:07<00:00, 3548.97 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3344.17 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2262.60 examples/s]
Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1685.99 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3126.51 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1415.55 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1953.64 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1687.93 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 3112.87 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1726.93 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3075.60 examples/s]Filter (num_proc=8):  86%|████████▌ | 15000/17457 [00:06<00:00, 2912.66 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1675.05 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2343.33 examples/s]
Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 2561.22 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  94%|█████████▎| 16365/17457 [00:07<00:00, 3648.97 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1478.84 examples/s]Filter (num_proc=8):  93%|█████████▎| 16182/17457 [00:07<00:00, 3095.34 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1999.83 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1462.63 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 3101.21 examples/s]Filter (num_proc=8):  99%|█████████▉| 17275/17457 [00:07<00:00, 3124.20 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2325.04 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2334.19 examples/s]
Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1944.16 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2232.51 examples/s]
Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2289.47 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  94%|█████████▎| 16365/17457 [00:07<00:00, 3595.43 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3548.41 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 283.69 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 517.06 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3339.79 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2263.93 examples/s]
Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2289.83 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 285.46 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 636.77 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 516.13 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 285.19 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 288.36 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 520.04 examples/s]
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 639.12 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 519.51 examples/s]
Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 292.07 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 286.22 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 651.88 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 528.19 examples/s]
Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 463.93 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 623.16 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 502.27 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2118.12 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3212.04 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 461.46 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 452.11 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3968.36 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2101.95 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2059.28 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3096.74 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3136.56 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 446.36 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2123.52 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3797.06 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3665.78 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 2940.21 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3614.21 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:02<00:19, 255.32 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:04<00:00, 1366.53 examples/s]
Map (num_proc=8):  25%|██▌       | 1402/5604 [00:02<00:07, 564.62 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:03<00:00, 1434.09 examples/s]
Map (num_proc=8): 100%|██████████| 5604/5604 [00:03<00:00, 1428.27 examples/s]
Map (num_proc=8): 100%|██████████| 5604/5604 [00:03<00:00, 1578.15 examples/s]
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:03<00:21, 224.06 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:03<00:04, 863.72 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:03<00:02, 1315.47 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:03<00:22, 219.02 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:03<00:21, 228.75 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:03<00:04, 770.36 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:03<00:01, 1659.25 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:03<00:02, 1111.23 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:03<00:01, 1450.24 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:03<00:01, 1384.93 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:03<00:00, 2130.06 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:03<00:00, 2076.63 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:04<00:00, 2282.30 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:04<00:00, 1672.15 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 953.75 examples/s] 
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 965.42 examples/s] 
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 996.54 examples/s] 
Map (num_proc=2):  50%|█████     | 122/243 [00:02<00:02, 43.04 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:02<00:02, 43.47 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:02<00:02, 41.41 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:02<00:02, 43.47 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 1000.23 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:03<00:00, 95.43 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:02<00:00, 99.89 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:02<00:00, 99.26 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:02<00:00, 97.23 examples/s]Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2): 100%|██████████| 243/243 [00:03<00:00, 74.43 examples/s]
Size of the train set: 3901. Size of the validation set: 173
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
prepare all done!
prepare all done!
prepare all done!
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
prepare all done!
Map (num_proc=2): 100%|██████████| 243/243 [00:03<00:00, 75.25 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:03<00:00, 74.53 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:03<00:00, 75.14 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 4096)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
prepare all done!
prepare all done!
prepare all done!
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 160.44 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 270.92 examples/s]
Size of the train set: 3901. Size of the validation set: 173
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
prepare all done!
mll zero 3
Parameter Offload: Total persistent parameters: 4460544 in 129 params
:::MLLOG {"namespace": "", "time_ms": 1709181895342, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 92}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "Closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 96}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 100}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 103}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 107}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 111}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": "8", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 119}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 125}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 129}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "seed", "value": 666, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 800, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 135}}
:::MLLOG {"namespace": "", "time_ms": 1709181895344, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0005, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1709181895345, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 138}}
:::MLLOG {"namespace": "", "time_ms": 1709181895345, "event_type": "INTERVAL_START", "key": "run_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 139}}
  0%|          | 0/800 [00:00<?, ?it/s]/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/800 [00:25<5:40:19, 25.56s/it]  0%|          | 2/800 [00:38<4:01:42, 18.17s/it]                                                 {'loss': 4.5372, 'learning_rate': 0.0004999922894111975, 'epoch': 0.0}
  0%|          | 2/800 [00:38<4:01:42, 18.17s/it]:::MLLOG {"namespace": "", "time_ms": 1709181933931, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 4.5372, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 157, "step_num": 2}}
  0%|          | 3/800 [00:51<3:30:08, 15.82s/it]                                                 {'loss': 4.4078, 'learning_rate': 0.0004999826512866693, 'epoch': 0.01}
  0%|          | 3/800 [00:51<3:30:08, 15.82s/it]  0%|          | 4/800 [01:04<3:15:13, 14.72s/it]                                                 {'loss': 4.29, 'learning_rate': 0.0004999691581204152, 'epoch': 0.01}
  0%|          | 4/800 [01:04<3:15:13, 14.72s/it]:::MLLOG {"namespace": "", "time_ms": 1709181959971, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 4.29, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 157, "step_num": 4}}
  1%|          | 5/800 [01:17<3:06:51, 14.10s/it]                                                 {'loss': 4.1959, 'learning_rate': 0.0004999518101205162, 'epoch': 0.01}
  1%|          | 5/800 [01:17<3:06:51, 14.10s/it]  1%|          | 6/800 [01:30<3:01:46, 13.74s/it]                                                 {'loss': 4.0258, 'learning_rate': 0.0004999306075545002, 'epoch': 0.01}
  1%|          | 6/800 [01:30<3:01:46, 13.74s/it]