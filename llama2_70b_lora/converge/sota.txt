[2024-03-19 18:22:35,568] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:D2yd7x1wqyy7bw4aMT9GD0WnqMvvOECYUAvu45kGxWQ failed
[2024-03-19 18:22:37,966] [INFO] [runner.py:463:main] Using IP address of 172.16.1.14 for node compute14
[2024-03-19 18:22:37,969] [INFO] [runner.py:568:main] cmd = mpirun -n 8 -ppn 8 -hostfile hostfile_mpich -genv PYTHONSTARTUP=/etc/pythonstart -genv PYTHONPATH=/home/maliangl/ft/reference/llama2_70b_lora -genv MASTER_ADDR 172.16.1.14 -genv MASTER_PORT 29500 -genv WORLD_SIZE 8 -genv LOCAL_SIZE 8 -hosts compute14 /home/maliangl/miniconda3/envs/ft0306/bin/python -u /home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/deepspeed/launcher/launcher_helper.py --launcher mpich scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,317] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,319] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,903] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:43,902] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft0306/bin/python -u scripts/train.py --model_path /scratch/users/tianmuli/llama2-70b-fused-qkv-mlperf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 24 --eval_steps 48 --output_dir ./converge_home --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 4e-4 --weight_decay 0.0001 --max_grad_norm 0.3 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 32 --lora_dropout 0.1 --max_steps 1024 --seed 42 --lora_target_modules qkv_proj,o_proj
[2024-03-19 18:22:50,356] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,356] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,356] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,356] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,358] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,358] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,360] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:50,363] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-03-19 18:22:51,232] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,233] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,234] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,234] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,295] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,295] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,309] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,309] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,310] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,310] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,316] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,316] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,316] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl
[2024-03-19 18:22:51,316] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,316] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:22:51,327] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-03-19 18:22:51,327] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-19 18:23:01,357] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 563, num_elems = 68.98B
Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.85s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:51,  1.86s/it]Loading checkpoint shards:   3%|▎         | 1/29 [00:01<00:54,  1.94s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:48,  1.80s/it]Loading checkpoint shards:   7%|▋         | 2/29 [00:03<00:49,  1.83s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:47,  1.82s/it]Loading checkpoint shards:  10%|█         | 3/29 [00:05<00:48,  1.85s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.84s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:07<00:46,  1.86s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  17%|█▋        | 5/29 [00:09<00:43,  1.82s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.80s/it]Loading checkpoint shards:  21%|██        | 6/29 [00:10<00:41,  1.81s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  24%|██▍       | 7/29 [00:12<00:39,  1.79s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  28%|██▊       | 8/29 [00:14<00:38,  1.82s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.83s/it]Loading checkpoint shards:  31%|███       | 9/29 [00:16<00:36,  1.84s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:18<00:34,  1.81s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:19<00:32,  1.79s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:21<00:30,  1.78s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:23<00:28,  1.80s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.82s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:25<00:27,  1.83s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:28<00:23,  1.80s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:29<00:23,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:30<00:21,  1.80s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:32<00:20,  1.82s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:34<00:18,  1.84s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:36<00:16,  1.82s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:38<00:14,  1.80s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:39<00:12,  1.78s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:41<00:10,  1.80s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:43<00:09,  1.82s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:45<00:07,  1.80s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:46<00:05,  1.79s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:47<00:05,  1.79s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:48<00:03,  1.78s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:50<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.79s/it]
Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:52<00:00,  1.80s/it]
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:30<08:29, 32.28 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:32, 32.11 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:18, 77.81 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:34, 31.99 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:37, 31.82 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:37, 31.80 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 76.92 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:38, 31.74 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:37, 31.80 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:38, 31.71 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:21, 76.65 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:21, 76.78 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:01, 118.73 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:47, 134.47 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:14, 180.23 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:46, 266.32 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:02, 117.68 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:49, 132.34 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:41, 298.64 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:03, 117.11 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:49, 132.29 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:52, 237.78 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:41, 300.21 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:02, 216.64 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:05, 115.60 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:49, 131.76 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:16, 175.99 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:41, 300.67 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:52, 235.50 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:33, 343.67 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:29, 388.38 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:37, 304.41 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:30, 373.55 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:21, 489.37 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:27, 416.18 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:35, 326.96 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:20, 517.50 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:25, 406.02 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:29, 382.12 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:20, 517.84 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:38, 296.06 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:33<00:24, 425.99 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:19, 538.34 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:20, 509.13 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:17, 540.16 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:18, 509.77 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:19, 474.54 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:21, 441.44 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:18, 523.84 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:17, 546.32 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:21, 433.48 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:17, 552.78 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:17, 552.78 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:18, 523.84 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:17, 546.32 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:19, 474.54 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:21, 433.48 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:21, 441.44 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:17, 540.16 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:54<00:18, 509.77 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:01<01:17, 109.44 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:20, 104.50 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:48, 153.62 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:18, 108.35 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:19, 106.00 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:49, 150.86 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:50, 148.81 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:09, 120.83 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:17, 108.85 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:20, 105.52 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:19, 106.92 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:49, 151.44 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:50, 148.68 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:35, 180.66 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 194.29 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 191.12 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 191.20 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:06<00:34, 185.16 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:06<00:35, 180.35 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:06<00:37, 170.73 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:23, 230.04 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:26, 208.86 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:06<00:36, 177.38 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:06<00:16, 277.66 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:06<00:23, 227.80 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:09, 372.31 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:13, 318.36 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:14, 305.19 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:24, 225.00 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 493.40 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:07<00:14, 316.83 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:08, 426.20 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:07<00:07, 444.48 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 544.02 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 585.87 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:07<00:04, 607.75 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:07<00:03, 571.30 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:04, 491.37 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:24, 222.84 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:24, 222.07 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:08<00:14, 303.33 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:08<00:14, 306.55 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:26, 205.18 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:27, 200.46 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:03, 525.25 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:08<00:08, 417.85 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:09<00:08, 422.80 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:08<00:16, 267.93 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:09<00:16, 264.58 examples/s]Map (num_proc=8):  77%|███████▋  | 13365/17457 [01:09<00:13, 294.97 examples/s]Map (num_proc=8):  87%|████████▋ | 15182/17457 [01:09<00:03, 594.17 examples/s]Map (num_proc=8):  77%|███████▋  | 13365/17457 [01:09<00:13, 294.69 examples/s]Map (num_proc=8):  82%|████████▏ | 14365/17457 [01:09<00:07, 416.39 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 556.54 examples/s]Map (num_proc=8):  87%|████████▋ | 15182/17457 [01:09<00:03, 581.59 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 593.02 examples/s]Map (num_proc=8):  82%|████████▏ | 14365/17457 [01:09<00:07, 413.17 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 615.55 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 599.65 examples/s]Map (num_proc=8):  95%|█████████▍| 16547/17457 [01:10<00:01, 505.57 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 685.10 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 621.70 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 650.79 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:11<00:01, 627.53 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:12<00:02, 317.20 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 358.28 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:13<00:01, 325.49 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:02, 360.57 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:13<00:01, 388.33 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:01, 351.71 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:13<00:01, 390.34 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 394.02 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:13<00:00, 413.37 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:13<00:00, 460.26 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:13<00:00, 357.52 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:14<00:00, 406.53 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:14<00:00, 387.57 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 357.18 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:01, 367.05 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 347.00 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 381.97 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 280.48 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:15<00:01, 369.27 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 232.36 examples/s]
Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:15<00:01, 384.09 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 232.01 examples/s]
Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 388.48 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 365.37 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 394.30 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 230.68 examples/s]
Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 384.34 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 284.98 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:15<00:02, 349.11 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 230.14 examples/s]
Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 390.86 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 413.48 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 395.06 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 413.87 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 229.01 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:16<00:00, 367.63 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 421.94 examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 400.52 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 228.26 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 360.01 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 227.44 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 226.94 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.15 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.26 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.28 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.22 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.24 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.45 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.71 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.06 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.29 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.88 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.28 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.31 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.25 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.35 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.61 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.25 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.21 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.99 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.83 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 31.38 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.58 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.55 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.24 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 31.18 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:52, 312.98 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 305.25 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:12, 1136.37 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1933.54 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1619.69 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:03<00:03, 2902.34 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:03, 2977.46 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 309.59 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:12, 1143.11 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:52, 311.66 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:12, 1141.44 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3726.14 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:05, 2171.85 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 308.84 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1971.89 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:03<00:03, 3429.41 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3458.11 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:53, 310.05 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:12, 1143.63 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:04, 2720.16 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:52, 311.27 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3974.48 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 304.09 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1562.83 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:12, 1113.82 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:04, 2577.67 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1576.22 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:06, 1387.29 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1792.50 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1908.55 examples/s]Filter (num_proc=8):  86%|████████▌ | 15000/17457 [00:06<00:00, 3412.62 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1638.56 examples/s]Filter (num_proc=8):  74%|███████▍  | 13000/17457 [00:06<00:01, 2948.28 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1438.12 examples/s]Filter (num_proc=8):  94%|█████████▎| 16365/17457 [00:06<00:00, 3939.43 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2155.39 examples/s]Filter (num_proc=8):  94%|█████████▎| 16365/17457 [00:07<00:00, 4227.68 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 2921.07 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1650.46 examples/s]Filter (num_proc=8):  93%|█████████▎| 16182/17457 [00:06<00:00, 3837.24 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 3379.14 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1715.26 examples/s]Filter (num_proc=8):  86%|████████▌ | 15000/17457 [00:06<00:00, 2920.47 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3889.33 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2308.51 examples/s]
Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2304.12 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  93%|█████████▎| 16182/17457 [00:07<00:00, 4052.53 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:06<00:06, 1441.37 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:06<00:08, 1278.27 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1521.16 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3487.62 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2335.87 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:06<00:06, 1484.50 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2100.55 examples/s]Filter (num_proc=8):  98%|█████████▊| 17093/17457 [00:07<00:00, 3093.73 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1579.47 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 2882.43 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3537.32 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2368.22 examples/s]
Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:02, 2504.89 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2283.50 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  87%|████████▋ | 15182/17457 [00:06<00:00, 3323.99 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:01, 2867.79 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1845.12 examples/s]Filter (num_proc=8):  74%|███████▍  | 13000/17457 [00:06<00:01, 3423.56 examples/s]Filter (num_proc=8):  95%|█████████▍| 16547/17457 [00:07<00:00, 3775.41 examples/s]Filter (num_proc=8):  81%|████████  | 14183/17457 [00:06<00:00, 3785.73 examples/s]Filter (num_proc=8):  82%|████████▏ | 14364/17457 [00:07<00:00, 3297.12 examples/s]Filter (num_proc=8):  86%|████████▋ | 15093/17457 [00:07<00:00, 3431.32 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3134.73 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2258.45 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 292.66 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 646.72 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 260.08 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 527.83 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 579.28 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 291.31 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:02<00:00, 473.36 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 641.86 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 524.19 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 295.87 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 293.54 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 653.63 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 532.92 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 631.18 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 518.99 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 293.79 examples/s]Filter (num_proc=8):  92%|█████████▏| 16092/17457 [00:09<00:00, 1847.92 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 646.29 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 527.67 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=8):  92%|█████████▏| 16093/17457 [00:09<00:00, 1488.31 examples/s]Filter (num_proc=8):  98%|█████████▊| 17092/17457 [00:09<00:00, 2079.41 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 460.12 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 456.07 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2106.16 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2101.01 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 451.08 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3074.31 examples/s]Filter (num_proc=8):  98%|█████████▊| 17093/17457 [00:09<00:00, 1620.50 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2065.99 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2744.24 examples/s]
Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3021.53 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:10<00:00, 1744.57 examples/s]
Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 450.80 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 4113.48 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 464.96 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3054.04 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:01<00:02, 1545.80 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2147.00 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2539.74 examples/s]
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2630.93 examples/s]
Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:01<00:00, 2707.53 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3077.95 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:10<00:00, 1670.82 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 206.85 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2786.07 examples/s]
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 232.47 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2548.10 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 340.97 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 379.31 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 237.64 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:10, 458.29 examples/s]prepare all done!
prepare all done!
prepare all done!
Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 240.42 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 393.67 examples/s]
Size of the train set: 3901. Size of the validation set: 173
prepare all done!
Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 394.63 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 235.38 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:01<00:02, 1538.75 examples/s]prepare all done!
mll zero 3
mll zero 3
mll zero 3
Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 385.36 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2):  50%|████▉     | 121/243 [00:00<00:00, 223.00 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:01<00:00, 2689.87 examples/s]mll zero 3
prepare all done!
Map (num_proc=2):  50%|████▉     | 121/243 [00:00<00:00, 191.08 examples/s]
Size of the train set: 3901. Size of the validation set: 173
mll zero 3
prepare all done!
Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2785.53 examples/s]
Size of the train set: 3901. Size of the validation set: 173
mll zero 3
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): CustomLlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 8192)
        (layers): ModuleList(
          (0-79): 80 x LlamaDecoderLayer(
            (self_attn): LlamaSdpaAttention(
              (qkv_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=10240, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=10240, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=8192, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=8192, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
    )
  )
)
prepare all done!
mll zero 3
mll zero 3
Parameter Offload: Total persistent parameters: 1318912 in 161 params
  0%|          | 0/1024 [00:00<?, ?it/s]/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft0306/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/1024 [00:48<13:42:29, 48.24s/it]  0%|          | 2/1024 [01:22<11:21:37, 40.02s/it]  0%|          | 3/1024 [01:56<10:33:29, 37.23s/it]  0%|          | 4/1024 [02:30<10:10:35, 35.92s/it]  0%|          | 5/1024 [03:04<9:57:57, 35.21s/it]   1%|          | 6/1024 [03:38<9:50:12, 34.79s/it]  1%|          | 7/1024 [04:12<9:45:15, 34.53s/it]  1%|          | 8/1024 [04:46<9:41:49, 34.36s/it]  1%|          | 9/1024 [05:20<9:39:26, 34.25s/it]  1%|          | 10/1024 [05:54<9:37:44, 34.19s/it]  1%|          | 11/1024 [06:28<9:36:26, 34.14s/it]  1%|          | 12/1024 [07:02<9:35:19, 34.11s/it]  1%|▏         | 13/1024 [07:36<9:34:20, 34.09s/it]  1%|▏         | 14/1024 [08:10<9:33:31, 34.07s/it]  1%|▏         | 15/1024 [08:44<9:32:44, 34.06s/it]  2%|▏         | 16/1024 [09:18<9:32:04, 34.05s/it]  2%|▏         | 17/1024 [09:52<9:31:24, 34.05s/it]  2%|▏         | 18/1024 [10:26<9:30:54, 34.05s/it]  2%|▏         | 19/1024 [11:00<9:30:19, 34.05s/it]  2%|▏         | 20/1024 [11:34<9:29:45, 34.05s/it]  2%|▏         | 21/1024 [12:08<9:29:19, 34.06s/it]  2%|▏         | 22/1024 [12:42<9:28:47, 34.06s/it]  2%|▏         | 23/1024 [13:16<9:28:17, 34.06s/it]  2%|▏         | 24/1024 [13:50<9:27:48, 34.07s/it]                                                   {'loss': 2.2348, 'grad_norm': 0.26414050209552525, 'learning_rate': 0.00039945809133573807, 'epoch': 0.05}
  2%|▏         | 24/1024 [13:50<9:27:48, 34.07s/it]  2%|▏         | 25/1024 [14:25<9:27:22, 34.08s/it]  3%|▎         | 26/1024 [14:59<9:26:49, 34.08s/it]  3%|▎         | 27/1024 [15:33<9:26:17, 34.08s/it]  3%|▎         | 28/1024 [16:07<9:25:49, 34.09s/it]  3%|▎         | 29/1024 [16:41<9:25:16, 34.09s/it]  3%|▎         | 30/1024 [17:15<9:24:45, 34.09s/it]  3%|▎         | 31/1024 [17:49<9:24:06, 34.08s/it]  3%|▎         | 32/1024 [18:23<9:23:31, 34.08s/it]  3%|▎         | 33/1024 [18:57<9:22:52, 34.08s/it]  3%|▎         | 34/1024 [19:31<9:22:15, 34.08s/it]  3%|▎         | 35/1024 [20:05<9:21:39, 34.07s/it]  4%|▎         | 36/1024 [20:39<9:21:04, 34.07s/it]  4%|▎         | 37/1024 [21:14<9:20:25, 34.07s/it]  4%|▎         | 38/1024 [21:48<9:19:50, 34.07s/it]  4%|▍         | 39/1024 [22:22<9:19:22, 34.07s/it]  4%|▍         | 40/1024 [22:56<9:18:54, 34.08s/it]  4%|▍         | 41/1024 [23:30<9:18:18, 34.08s/it]  4%|▍         | 42/1024 [24:04<9:17:40, 34.07s/it]  4%|▍         | 43/1024 [24:38<9:17:10, 34.08s/it]  4%|▍         | 44/1024 [25:12<9:16:36, 34.08s/it]  4%|▍         | 45/1024 [25:46<9:16:02, 34.08s/it]  4%|▍         | 46/1024 [26:20<9:15:27, 34.08s/it]  5%|▍         | 47/1024 [26:54<9:14:58, 34.08s/it]  5%|▍         | 48/1024 [27:28<9:14:26, 34.08s/it]                                                   {'loss': 1.3635, 'grad_norm': 0.15319200313387724, 'learning_rate': 0.0003978353019929562, 'epoch': 0.1}
  5%|▍         | 48/1024 [27:28<9:14:26, 34.08s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:51,  5.57s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.83s/it][A
 18%|█▊        | 4/22 [00:33<02:42,  9.02s/it][A
 23%|██▎       | 5/22 [00:44<02:45,  9.71s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.14s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.42s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.72s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.81s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.87s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.91s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.94s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.96s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.97s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.98s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 10.99s/it][A
 82%|████████▏ | 18/22 [03:07<00:43, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.00s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.00s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A
                                               [A                                                   {'eval_loss': 0.9935545921325684, 'eval_runtime': 242.0557, 'eval_samples_per_second': 0.715, 'eval_steps_per_second': 0.091, 'epoch': 0.1}

100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A  5%|▍         | 48/1024 [31:30<9:14:26, 34.08s/it]
                                               [A  5%|▍         | 49/1024 [32:05<28:55:00, 106.77s/it]  5%|▍         | 50/1024 [32:39<22:59:14, 84.96s/it]   5%|▍         | 51/1024 [33:13<18:50:23, 69.71s/it]  5%|▌         | 52/1024 [33:47<15:56:04, 59.02s/it]  5%|▌         | 53/1024 [34:21<13:54:02, 51.54s/it]  5%|▌         | 54/1024 [34:55<12:28:28, 46.30s/it]  5%|▌         | 55/1024 [35:29<11:28:27, 42.63s/it]  5%|▌         | 56/1024 [36:03<10:46:21, 40.06s/it]  6%|▌         | 57/1024 [36:37<10:16:44, 38.27s/it]  6%|▌         | 58/1024 [37:11<9:55:53, 37.01s/it]   6%|▌         | 59/1024 [37:46<9:41:06, 36.13s/it]  6%|▌         | 60/1024 [38:20<9:30:35, 35.51s/it]  6%|▌         | 61/1024 [38:54<9:23:07, 35.09s/it]  6%|▌         | 62/1024 [39:28<9:17:42, 34.78s/it]  6%|▌         | 63/1024 [40:02<9:13:46, 34.58s/it]  6%|▋         | 64/1024 [40:36<9:11:25, 34.46s/it]  6%|▋         | 65/1024 [41:10<9:08:57, 34.35s/it]  6%|▋         | 66/1024 [41:44<9:07:05, 34.26s/it]  7%|▋         | 67/1024 [42:18<9:05:40, 34.21s/it]  7%|▋         | 68/1024 [42:52<9:04:31, 34.18s/it]  7%|▋         | 69/1024 [43:27<9:03:36, 34.15s/it]  7%|▋         | 70/1024 [44:01<9:02:43, 34.13s/it]  7%|▋         | 71/1024 [44:35<9:01:55, 34.12s/it]  7%|▋         | 72/1024 [45:09<9:01:12, 34.11s/it]                                                   {'loss': 1.3405, 'grad_norm': 0.15298265601236716, 'learning_rate': 0.0003951404260077057, 'epoch': 0.15}
  7%|▋         | 72/1024 [45:09<9:01:12, 34.11s/it]  7%|▋         | 73/1024 [45:43<9:00:36, 34.11s/it]  7%|▋         | 74/1024 [46:17<8:59:57, 34.10s/it]  7%|▋         | 75/1024 [46:51<8:59:16, 34.10s/it]  7%|▋         | 76/1024 [47:25<8:58:44, 34.10s/it]  8%|▊         | 77/1024 [47:59<8:58:09, 34.10s/it]  8%|▊         | 78/1024 [48:33<8:57:39, 34.10s/it]  8%|▊         | 79/1024 [49:07<8:57:04, 34.10s/it]  8%|▊         | 80/1024 [49:42<8:56:25, 34.09s/it]  8%|▊         | 81/1024 [50:16<8:55:54, 34.10s/it]  8%|▊         | 82/1024 [50:50<8:55:16, 34.09s/it]  8%|▊         | 83/1024 [51:24<8:54:41, 34.09s/it]  8%|▊         | 84/1024 [51:58<8:54:07, 34.09s/it]  8%|▊         | 85/1024 [52:32<8:53:39, 34.10s/it]  8%|▊         | 86/1024 [53:06<8:52:57, 34.09s/it]  8%|▊         | 87/1024 [53:40<8:52:24, 34.09s/it]  9%|▊         | 88/1024 [54:14<8:51:44, 34.09s/it]  9%|▊         | 89/1024 [54:48<8:51:10, 34.09s/it]  9%|▉         | 90/1024 [55:22<8:50:36, 34.09s/it]  9%|▉         | 91/1024 [55:57<8:49:58, 34.08s/it]  9%|▉         | 92/1024 [56:31<8:49:26, 34.08s/it]  9%|▉         | 93/1024 [57:05<8:48:50, 34.08s/it]  9%|▉         | 94/1024 [57:39<8:48:18, 34.08s/it]  9%|▉         | 95/1024 [58:13<8:47:50, 34.09s/it]  9%|▉         | 96/1024 [58:47<8:47:17, 34.09s/it]                                                   {'loss': 1.3199, 'grad_norm': 0.13453143870446596, 'learning_rate': 0.0003913880671464418, 'epoch': 0.2}
  9%|▉         | 96/1024 [58:47<8:47:17, 34.09s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:10<01:49,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.79s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.69s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.41s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.72s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.81s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.87s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.91s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.94s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.96s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.97s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.98s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 10.99s/it][A
 82%|████████▏ | 18/22 [03:07<00:43, 10.99s/it][A
 86%|████████▋ | 19/22 [03:18<00:32, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:21, 11.00s/it][A
 95%|█████████▌| 21/22 [03:40<00:10, 11.00s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A
                                               [A                                                   {'eval_loss': 0.9625189304351807, 'eval_runtime': 242.0843, 'eval_samples_per_second': 0.715, 'eval_steps_per_second': 0.091, 'epoch': 0.2}

100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A  9%|▉         | 96/1024 [1:02:49<8:47:17, 34.09s/it]
                                               [A  9%|▉         | 97/1024 [1:03:23<27:29:00, 106.73s/it] 10%|▉         | 98/1024 [1:03:57<21:50:56, 84.94s/it]  10%|▉         | 99/1024 [1:04:31<17:54:23, 69.69s/it] 10%|▉         | 100/1024 [1:05:05<15:08:41, 59.01s/it] 10%|▉         | 101/1024 [1:05:40<13:12:46, 51.53s/it] 10%|▉         | 102/1024 [1:06:14<11:51:27, 46.30s/it] 10%|█         | 103/1024 [1:06:48<10:54:31, 42.64s/it] 10%|█         | 104/1024 [1:07:22<10:14:27, 40.07s/it] 10%|█         | 105/1024 [1:07:56<9:46:20, 38.28s/it]  10%|█         | 106/1024 [1:08:30<9:26:24, 37.02s/it] 10%|█         | 107/1024 [1:09:04<9:12:23, 36.14s/it] 11%|█         | 108/1024 [1:09:38<9:02:16, 35.52s/it] 11%|█         | 109/1024 [1:10:12<8:55:03, 35.09s/it] 11%|█         | 110/1024 [1:10:46<8:49:55, 34.79s/it] 11%|█         | 111/1024 [1:11:20<8:46:11, 34.58s/it] 11%|█         | 112/1024 [1:11:55<8:43:22, 34.43s/it] 11%|█         | 113/1024 [1:12:29<8:41:14, 34.33s/it] 11%|█         | 114/1024 [1:13:03<8:39:37, 34.26s/it] 11%|█         | 115/1024 [1:13:37<8:38:18, 34.21s/it] 11%|█▏        | 116/1024 [1:14:11<8:37:10, 34.17s/it] 11%|█▏        | 117/1024 [1:14:45<8:36:13, 34.15s/it] 12%|█▏        | 118/1024 [1:15:19<8:35:26, 34.14s/it] 12%|█▏        | 119/1024 [1:15:53<8:34:41, 34.12s/it] 12%|█▏        | 120/1024 [1:16:27<8:33:58, 34.11s/it]                                                      {'loss': 1.3273, 'grad_norm': 0.1460968811963887, 'learning_rate': 0.0003865985597669478, 'epoch': 0.25}
 12%|█▏        | 120/1024 [1:16:27<8:33:58, 34.11s/it] 12%|█▏        | 121/1024 [1:17:01<8:33:23, 34.11s/it] 12%|█▏        | 122/1024 [1:17:35<8:32:43, 34.11s/it] 12%|█▏        | 123/1024 [1:18:10<8:32:06, 34.10s/it] 12%|█▏        | 124/1024 [1:18:44<8:31:27, 34.10s/it] 12%|█▏        | 125/1024 [1:19:18<8:30:50, 34.09s/it] 12%|█▏        | 126/1024 [1:19:52<8:30:13, 34.09s/it] 12%|█▏        | 127/1024 [1:20:26<8:29:38, 34.09s/it] 12%|█▎        | 128/1024 [1:21:00<8:29:03, 34.09s/it] 13%|█▎        | 129/1024 [1:21:34<8:28:30, 34.09s/it] 13%|█▎        | 130/1024 [1:22:08<8:27:57, 34.09s/it] 13%|█▎        | 131/1024 [1:22:42<8:27:28, 34.10s/it] 13%|█▎        | 132/1024 [1:23:16<8:26:53, 34.10s/it] 13%|█▎        | 133/1024 [1:23:51<8:26:21, 34.10s/it] 13%|█▎        | 134/1024 [1:24:25<8:25:48, 34.10s/it] 13%|█▎        | 135/1024 [1:24:59<8:25:18, 34.10s/it] 13%|█▎        | 136/1024 [1:25:33<8:24:47, 34.11s/it] 13%|█▎        | 137/1024 [1:26:07<8:24:13, 34.11s/it] 13%|█▎        | 138/1024 [1:26:41<8:23:32, 34.10s/it] 14%|█▎        | 139/1024 [1:27:15<8:22:59, 34.10s/it] 14%|█▎        | 140/1024 [1:27:49<8:22:26, 34.10s/it] 14%|█▍        | 141/1024 [1:28:23<8:21:51, 34.10s/it] 14%|█▍        | 142/1024 [1:28:57<8:21:09, 34.09s/it] 14%|█▍        | 143/1024 [1:29:32<8:20:34, 34.09s/it] 14%|█▍        | 144/1024 [1:30:06<8:19:59, 34.09s/it]                                                      {'loss': 1.3178, 'grad_norm': 0.10661894278070924, 'learning_rate': 0.0003807978586246887, 'epoch': 0.3}
 14%|█▍        | 144/1024 [1:30:06<8:19:59, 34.09s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.69s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.41s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.81s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.87s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.91s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.94s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.96s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 10.99s/it][A
 82%|████████▏ | 18/22 [03:07<00:43, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9457768201828003, 'eval_runtime': 242.1663, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.3}
 14%|█▍        | 144/1024 [1:34:08<8:19:59, 34.09s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 14%|█▍        | 145/1024 [1:34:42<26:04:07, 106.77s/it] 14%|█▍        | 146/1024 [1:35:16<20:43:21, 84.97s/it]  14%|█▍        | 147/1024 [1:35:50<16:58:58, 69.71s/it] 14%|█▍        | 148/1024 [1:36:24<14:21:50, 59.03s/it] 15%|█▍        | 149/1024 [1:36:58<12:31:52, 51.56s/it] 15%|█▍        | 150/1024 [1:37:33<11:14:49, 46.33s/it] 15%|█▍        | 151/1024 [1:38:07<10:20:45, 42.66s/it] 15%|█▍        | 152/1024 [1:38:41<9:43:20, 40.14s/it]  15%|█▍        | 153/1024 [1:39:15<9:16:22, 38.33s/it] 15%|█▌        | 154/1024 [1:39:49<8:57:25, 37.06s/it] 15%|█▌        | 155/1024 [1:40:23<8:44:03, 36.18s/it] 15%|█▌        | 156/1024 [1:40:57<8:34:24, 35.56s/it] 15%|█▌        | 157/1024 [1:41:31<8:27:29, 35.12s/it] 15%|█▌        | 158/1024 [1:42:06<8:22:31, 34.82s/it] 16%|█▌        | 159/1024 [1:42:40<8:18:52, 34.60s/it] 16%|█▌        | 160/1024 [1:43:14<8:16:01, 34.45s/it] 16%|█▌        | 161/1024 [1:43:48<8:13:54, 34.34s/it] 16%|█▌        | 162/1024 [1:44:22<8:12:16, 34.27s/it] 16%|█▌        | 163/1024 [1:44:56<8:10:51, 34.21s/it] 16%|█▌        | 164/1024 [1:45:30<8:09:49, 34.17s/it] 16%|█▌        | 165/1024 [1:46:04<8:08:52, 34.15s/it] 16%|█▌        | 166/1024 [1:46:38<8:08:07, 34.14s/it] 16%|█▋        | 167/1024 [1:47:12<8:07:27, 34.13s/it] 16%|█▋        | 168/1024 [1:47:46<8:06:46, 34.12s/it]                                                      {'loss': 1.3198, 'grad_norm': 0.15775982777324146, 'learning_rate': 0.0003740173982217423, 'epoch': 0.34}
 16%|█▋        | 168/1024 [1:47:46<8:06:46, 34.12s/it] 17%|█▋        | 169/1024 [1:48:21<8:06:15, 34.12s/it] 17%|█▋        | 170/1024 [1:48:55<8:05:37, 34.12s/it] 17%|█▋        | 171/1024 [1:49:29<8:05:00, 34.12s/it] 17%|█▋        | 172/1024 [1:50:03<8:04:21, 34.11s/it] 17%|█▋        | 173/1024 [1:50:37<8:03:50, 34.11s/it] 17%|█▋        | 174/1024 [1:51:11<8:03:12, 34.11s/it] 17%|█▋        | 175/1024 [1:51:45<8:02:40, 34.11s/it] 17%|█▋        | 176/1024 [1:52:19<8:02:09, 34.12s/it] 17%|█▋        | 177/1024 [1:52:53<8:01:34, 34.11s/it] 17%|█▋        | 178/1024 [1:53:28<8:00:57, 34.11s/it] 17%|█▋        | 179/1024 [1:54:02<8:00:23, 34.11s/it] 18%|█▊        | 180/1024 [1:54:36<7:59:50, 34.11s/it] 18%|█▊        | 181/1024 [1:55:10<7:59:16, 34.11s/it] 18%|█▊        | 182/1024 [1:55:44<7:58:40, 34.11s/it] 18%|█▊        | 183/1024 [1:56:18<7:58:06, 34.11s/it] 18%|█▊        | 184/1024 [1:56:52<7:57:33, 34.11s/it] 18%|█▊        | 185/1024 [1:57:26<7:56:55, 34.11s/it] 18%|█▊        | 186/1024 [1:58:00<7:56:15, 34.10s/it] 18%|█▊        | 187/1024 [1:58:35<7:55:43, 34.10s/it] 18%|█▊        | 188/1024 [1:59:09<7:55:04, 34.10s/it] 18%|█▊        | 189/1024 [1:59:43<7:54:31, 34.10s/it] 19%|█▊        | 190/1024 [2:00:17<7:53:55, 34.09s/it] 19%|█▊        | 191/1024 [2:00:51<7:53:20, 34.09s/it] 19%|█▉        | 192/1024 [2:01:25<7:52:49, 34.10s/it]                                                      {'loss': 1.3005, 'grad_norm': 0.1451019967263798, 'learning_rate': 0.0003662939224605091, 'epoch': 0.39}
 19%|█▉        | 192/1024 [2:01:25<7:52:49, 34.10s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:10<01:49,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.79s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.69s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.41s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.82s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.95s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.97s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:55, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.01s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.01s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9398214817047119, 'eval_runtime': 242.2773, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.39}
 19%|█▉        | 192/1024 [2:05:27<7:52:49, 34.10s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 19%|█▉        | 193/1024 [2:06:01<24:39:14, 106.80s/it] 19%|█▉        | 194/1024 [2:06:36<19:35:45, 84.99s/it]  19%|█▉        | 195/1024 [2:07:10<16:03:27, 69.73s/it] 19%|█▉        | 196/1024 [2:07:44<13:34:49, 59.05s/it] 19%|█▉        | 197/1024 [2:08:18<11:50:43, 51.56s/it] 19%|█▉        | 198/1024 [2:08:52<10:37:48, 46.33s/it] 19%|█▉        | 199/1024 [2:09:26<9:46:39, 42.67s/it]  20%|█▉        | 200/1024 [2:10:00<9:10:41, 40.10s/it] 20%|█▉        | 201/1024 [2:10:34<8:45:20, 38.30s/it] 20%|█▉        | 202/1024 [2:11:08<8:27:31, 37.05s/it] 20%|█▉        | 203/1024 [2:11:43<8:14:47, 36.16s/it] 20%|█▉        | 204/1024 [2:12:17<8:05:43, 35.54s/it] 20%|██        | 205/1024 [2:12:51<7:59:13, 35.11s/it] 20%|██        | 206/1024 [2:13:25<7:54:30, 34.81s/it] 20%|██        | 207/1024 [2:13:59<7:51:02, 34.59s/it] 20%|██        | 208/1024 [2:14:33<7:48:29, 34.45s/it] 20%|██        | 209/1024 [2:15:07<7:46:30, 34.34s/it] 21%|██        | 210/1024 [2:15:41<7:44:58, 34.27s/it] 21%|██        | 211/1024 [2:16:15<7:43:47, 34.23s/it] 21%|██        | 212/1024 [2:16:49<7:42:44, 34.19s/it] 21%|██        | 213/1024 [2:17:24<7:41:52, 34.17s/it] 21%|██        | 214/1024 [2:17:58<7:41:04, 34.15s/it] 21%|██        | 215/1024 [2:18:32<7:40:14, 34.13s/it] 21%|██        | 216/1024 [2:19:06<7:39:31, 34.12s/it]                                                      {'loss': 1.3262, 'grad_norm': 0.672467982877954, 'learning_rate': 0.0003576692855253213, 'epoch': 0.44}
 21%|██        | 216/1024 [2:19:06<7:39:31, 34.12s/it] 21%|██        | 217/1024 [2:19:40<7:38:56, 34.12s/it] 21%|██▏       | 218/1024 [2:20:14<7:38:14, 34.11s/it] 21%|██▏       | 219/1024 [2:20:48<7:37:41, 34.11s/it] 21%|██▏       | 220/1024 [2:21:22<7:37:01, 34.11s/it] 22%|██▏       | 221/1024 [2:21:56<7:36:26, 34.11s/it] 22%|██▏       | 222/1024 [2:22:31<7:35:56, 34.11s/it] 22%|██▏       | 223/1024 [2:23:05<7:35:23, 34.11s/it] 22%|██▏       | 224/1024 [2:23:39<7:34:49, 34.11s/it] 22%|██▏       | 225/1024 [2:24:13<7:34:14, 34.11s/it] 22%|██▏       | 226/1024 [2:24:47<7:33:39, 34.11s/it] 22%|██▏       | 227/1024 [2:25:21<7:33:05, 34.11s/it] 22%|██▏       | 228/1024 [2:25:55<7:32:32, 34.11s/it] 22%|██▏       | 229/1024 [2:26:29<7:31:59, 34.11s/it] 22%|██▏       | 230/1024 [2:27:03<7:31:24, 34.11s/it] 23%|██▎       | 231/1024 [2:27:38<7:30:50, 34.11s/it] 23%|██▎       | 232/1024 [2:28:12<7:30:14, 34.11s/it] 23%|██▎       | 233/1024 [2:28:46<7:29:36, 34.10s/it] 23%|██▎       | 234/1024 [2:29:20<7:29:01, 34.10s/it] 23%|██▎       | 235/1024 [2:29:54<7:28:33, 34.11s/it] 23%|██▎       | 236/1024 [2:30:28<7:27:55, 34.11s/it] 23%|██▎       | 237/1024 [2:31:02<7:27:18, 34.10s/it] 23%|██▎       | 238/1024 [2:31:36<7:26:43, 34.10s/it] 23%|██▎       | 239/1024 [2:32:10<7:26:05, 34.10s/it] 23%|██▎       | 240/1024 [2:32:44<7:25:25, 34.09s/it]                                                      {'loss': 1.3068, 'grad_norm': 0.18362330837321333, 'learning_rate': 0.00034819022507099186, 'epoch': 0.49}
 23%|██▎       | 240/1024 [2:32:44<7:25:25, 34.09s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.70s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.41s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.81s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.95s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.97s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.01s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9342045187950134, 'eval_runtime': 242.2394, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.49}
 23%|██▎       | 240/1024 [2:36:47<7:25:25, 34.09s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 24%|██▎       | 241/1024 [2:37:21<23:13:30, 106.78s/it] 24%|██▎       | 242/1024 [2:37:55<18:27:34, 84.98s/it]  24%|██▎       | 243/1024 [2:38:29<15:07:29, 69.72s/it] 24%|██▍       | 244/1024 [2:39:03<12:47:26, 59.03s/it] 24%|██▍       | 245/1024 [2:39:37<11:09:21, 51.56s/it] 24%|██▍       | 246/1024 [2:40:11<10:00:37, 46.32s/it] 24%|██▍       | 247/1024 [2:40:45<9:12:21, 42.65s/it]  24%|██▍       | 248/1024 [2:41:20<8:38:29, 40.09s/it] 24%|██▍       | 249/1024 [2:41:54<8:14:37, 38.29s/it] 24%|██▍       | 250/1024 [2:42:28<7:57:47, 37.04s/it] 25%|██▍       | 251/1024 [2:43:02<7:45:51, 36.16s/it] 25%|██▍       | 252/1024 [2:43:36<7:37:19, 35.54s/it] 25%|██▍       | 253/1024 [2:44:10<7:31:14, 35.12s/it] 25%|██▍       | 254/1024 [2:44:44<7:26:50, 34.82s/it] 25%|██▍       | 255/1024 [2:45:18<7:23:32, 34.61s/it] 25%|██▌       | 256/1024 [2:45:52<7:21:02, 34.46s/it] 25%|██▌       | 257/1024 [2:46:27<7:19:12, 34.36s/it] 25%|██▌       | 258/1024 [2:47:01<7:17:39, 34.28s/it] 25%|██▌       | 259/1024 [2:47:35<7:16:23, 34.23s/it] 25%|██▌       | 260/1024 [2:48:09<7:15:28, 34.20s/it] 25%|██▌       | 261/1024 [2:48:43<7:14:31, 34.17s/it] 26%|██▌       | 262/1024 [2:49:17<7:13:41, 34.15s/it] 26%|██▌       | 263/1024 [2:49:51<7:12:54, 34.13s/it] 26%|██▌       | 264/1024 [2:50:25<7:12:13, 34.12s/it]                                                      {'loss': 1.3239, 'grad_norm': 0.305378297241759, 'learning_rate': 0.0003379081089474134, 'epoch': 0.54}
 26%|██▌       | 264/1024 [2:50:25<7:12:13, 34.12s/it] 26%|██▌       | 265/1024 [2:50:59<7:11:33, 34.12s/it] 26%|██▌       | 266/1024 [2:51:34<7:10:54, 34.11s/it] 26%|██▌       | 267/1024 [2:52:08<7:10:20, 34.11s/it] 26%|██▌       | 268/1024 [2:52:42<7:09:45, 34.11s/it] 26%|██▋       | 269/1024 [2:53:16<7:09:10, 34.11s/it] 26%|██▋       | 270/1024 [2:53:50<7:08:33, 34.10s/it] 26%|██▋       | 271/1024 [2:54:24<7:07:59, 34.10s/it] 27%|██▋       | 272/1024 [2:54:58<7:07:28, 34.11s/it] 27%|██▋       | 273/1024 [2:55:32<7:06:52, 34.10s/it] 27%|██▋       | 274/1024 [2:56:06<7:06:20, 34.11s/it] 27%|██▋       | 275/1024 [2:56:40<7:05:49, 34.11s/it] 27%|██▋       | 276/1024 [2:57:15<7:05:16, 34.11s/it] 27%|██▋       | 277/1024 [2:57:49<7:04:39, 34.11s/it] 27%|██▋       | 278/1024 [2:58:23<7:04:04, 34.11s/it] 27%|██▋       | 279/1024 [2:58:57<7:03:31, 34.11s/it] 27%|██▋       | 280/1024 [2:59:31<7:02:57, 34.11s/it] 27%|██▋       | 281/1024 [3:00:05<7:02:24, 34.11s/it] 28%|██▊       | 282/1024 [3:00:39<7:01:51, 34.11s/it] 28%|██▊       | 283/1024 [3:01:13<7:01:17, 34.11s/it] 28%|██▊       | 284/1024 [3:01:47<7:00:42, 34.11s/it] 28%|██▊       | 285/1024 [3:02:22<7:00:05, 34.11s/it] 28%|██▊       | 286/1024 [3:02:56<6:59:28, 34.10s/it] 28%|██▊       | 287/1024 [3:03:30<6:58:52, 34.10s/it] 28%|██▊       | 288/1024 [3:04:04<6:58:17, 34.10s/it]                                                      {'loss': 1.2949, 'grad_norm': 0.12431246851020356, 'learning_rate': 0.0003268786568327291, 'epoch': 0.59}
 28%|██▊       | 288/1024 [3:04:04<6:58:17, 34.10s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:10<01:49,  5.50s/it][A
 14%|█▎        | 3/22 [00:21<02:28,  7.79s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.69s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.42s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.61s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.82s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.95s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.97s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.01s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.929967999458313, 'eval_runtime': 242.2925, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.59}
 28%|██▊       | 288/1024 [3:08:06<6:58:17, 34.10s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 28%|██▊       | 289/1024 [3:08:40<21:48:24, 106.81s/it] 28%|██▊       | 290/1024 [3:09:14<17:19:50, 85.00s/it]  28%|██▊       | 291/1024 [3:09:49<14:11:57, 69.74s/it] 29%|██▊       | 292/1024 [3:10:23<12:00:24, 59.05s/it] 29%|██▊       | 293/1024 [3:10:57<10:28:17, 51.57s/it] 29%|██▊       | 294/1024 [3:11:31<9:23:41, 46.33s/it]  29%|██▉       | 295/1024 [3:12:05<8:38:22, 42.66s/it] 29%|██▉       | 296/1024 [3:12:39<8:06:38, 40.11s/it] 29%|██▉       | 297/1024 [3:13:13<7:44:11, 38.31s/it] 29%|██▉       | 298/1024 [3:13:47<7:28:21, 37.05s/it] 29%|██▉       | 299/1024 [3:14:22<7:17:08, 36.18s/it] 29%|██▉       | 300/1024 [3:14:56<7:09:03, 35.56s/it] 29%|██▉       | 301/1024 [3:15:30<7:03:11, 35.12s/it] 29%|██▉       | 302/1024 [3:16:04<6:58:55, 34.81s/it] 30%|██▉       | 303/1024 [3:16:38<6:55:46, 34.60s/it] 30%|██▉       | 304/1024 [3:17:12<6:53:25, 34.45s/it] 30%|██▉       | 305/1024 [3:17:46<6:51:35, 34.35s/it] 30%|██▉       | 306/1024 [3:18:20<6:50:09, 34.28s/it] 30%|██▉       | 307/1024 [3:18:54<6:48:58, 34.22s/it] 30%|███       | 308/1024 [3:19:28<6:47:58, 34.19s/it] 30%|███       | 309/1024 [3:20:03<6:47:08, 34.17s/it] 30%|███       | 310/1024 [3:20:37<6:46:22, 34.15s/it] 30%|███       | 311/1024 [3:21:11<6:45:42, 34.14s/it] 30%|███       | 312/1024 [3:21:45<6:45:02, 34.13s/it]                                                      {'loss': 1.2911, 'grad_norm': 0.16914795954054876, 'learning_rate': 0.0003151616382835691, 'epoch': 0.64}
 30%|███       | 312/1024 [3:21:45<6:45:02, 34.13s/it] 31%|███       | 313/1024 [3:22:19<6:44:29, 34.13s/it] 31%|███       | 314/1024 [3:22:53<6:43:48, 34.12s/it] 31%|███       | 315/1024 [3:23:27<6:43:18, 34.13s/it] 31%|███       | 316/1024 [3:24:01<6:42:40, 34.12s/it] 31%|███       | 317/1024 [3:24:36<6:42:08, 34.13s/it] 31%|███       | 318/1024 [3:25:10<6:41:30, 34.12s/it] 31%|███       | 319/1024 [3:25:44<6:40:55, 34.12s/it] 31%|███▏      | 320/1024 [3:26:18<6:40:21, 34.12s/it] 31%|███▏      | 321/1024 [3:26:52<6:39:48, 34.12s/it] 31%|███▏      | 322/1024 [3:27:26<6:39:14, 34.12s/it] 32%|███▏      | 323/1024 [3:28:00<6:38:38, 34.12s/it] 32%|███▏      | 324/1024 [3:28:34<6:38:03, 34.12s/it] 32%|███▏      | 325/1024 [3:29:09<6:37:34, 34.13s/it] 32%|███▏      | 326/1024 [3:29:43<6:37:01, 34.13s/it] 32%|███▏      | 327/1024 [3:30:17<6:36:28, 34.13s/it] 32%|███▏      | 328/1024 [3:30:51<6:35:55, 34.13s/it] 32%|███▏      | 329/1024 [3:31:25<6:35:23, 34.13s/it] 32%|███▏      | 330/1024 [3:31:59<6:34:44, 34.13s/it] 32%|███▏      | 331/1024 [3:32:33<6:34:14, 34.13s/it] 32%|███▏      | 332/1024 [3:33:07<6:33:35, 34.13s/it] 33%|███▎      | 333/1024 [3:33:42<6:33:01, 34.13s/it] 33%|███▎      | 334/1024 [3:34:16<6:32:22, 34.12s/it] 33%|███▎      | 335/1024 [3:34:50<6:31:44, 34.11s/it] 33%|███▎      | 336/1024 [3:35:24<6:31:09, 34.11s/it]                                                      {'loss': 1.3022, 'grad_norm': 0.119653018811468, 'learning_rate': 0.0003028205488386443, 'epoch': 0.69}
 33%|███▎      | 336/1024 [3:35:24<6:31:09, 34.11s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  9.00s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.70s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.42s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.61s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.82s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.95s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.97s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9268410801887512, 'eval_runtime': 242.2858, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.69}
 33%|███▎      | 336/1024 [3:39:26<6:31:09, 34.11s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 33%|███▎      | 337/1024 [3:40:00<20:23:05, 106.82s/it] 33%|███▎      | 338/1024 [3:40:34<16:11:52, 85.00s/it]  33%|███▎      | 339/1024 [3:41:09<13:16:11, 69.74s/it] 33%|███▎      | 340/1024 [3:41:43<11:13:14, 59.06s/it] 33%|███▎      | 341/1024 [3:42:17<9:47:03, 51.57s/it]  33%|███▎      | 342/1024 [3:42:51<8:46:40, 46.34s/it] 33%|███▎      | 343/1024 [3:43:25<8:04:20, 42.67s/it] 34%|███▎      | 344/1024 [3:43:59<7:34:31, 40.11s/it] 34%|███▎      | 345/1024 [3:44:33<7:13:35, 38.31s/it] 34%|███▍      | 346/1024 [3:45:07<6:58:43, 37.06s/it] 34%|███▍      | 347/1024 [3:45:42<6:48:14, 36.18s/it] 34%|███▍      | 348/1024 [3:46:16<6:40:42, 35.57s/it] 34%|███▍      | 349/1024 [3:46:50<6:35:13, 35.13s/it] 34%|███▍      | 350/1024 [3:47:24<6:31:12, 34.83s/it] 34%|███▍      | 351/1024 [3:47:58<6:28:13, 34.61s/it] 34%|███▍      | 352/1024 [3:48:32<6:25:59, 34.46s/it] 34%|███▍      | 353/1024 [3:49:06<6:24:20, 34.37s/it] 35%|███▍      | 354/1024 [3:49:40<6:22:55, 34.29s/it] 35%|███▍      | 355/1024 [3:50:15<6:21:43, 34.24s/it] 35%|███▍      | 356/1024 [3:50:49<6:20:40, 34.19s/it] 35%|███▍      | 357/1024 [3:51:23<6:19:48, 34.17s/it] 35%|███▍      | 358/1024 [3:51:57<6:19:04, 34.15s/it] 35%|███▌      | 359/1024 [3:52:31<6:18:23, 34.14s/it] 35%|███▌      | 360/1024 [3:53:05<6:17:48, 34.14s/it]                                                      {'loss': 1.292, 'grad_norm': 0.17292004420296295, 'learning_rate': 0.00028992226593092135, 'epoch': 0.74}
 35%|███▌      | 360/1024 [3:53:05<6:17:48, 34.14s/it] 35%|███▌      | 361/1024 [3:53:39<6:17:13, 34.14s/it] 35%|███▌      | 362/1024 [3:54:13<6:16:37, 34.13s/it] 35%|███▌      | 363/1024 [3:54:47<6:15:55, 34.12s/it] 36%|███▌      | 364/1024 [3:55:22<6:15:21, 34.12s/it] 36%|███▌      | 365/1024 [3:55:56<6:14:47, 34.12s/it] 36%|███▌      | 366/1024 [3:56:30<6:14:11, 34.12s/it] 36%|███▌      | 367/1024 [3:57:04<6:13:37, 34.12s/it] 36%|███▌      | 368/1024 [3:57:38<6:13:06, 34.13s/it] 36%|███▌      | 369/1024 [3:58:12<6:12:31, 34.12s/it] 36%|███▌      | 370/1024 [3:58:46<6:11:57, 34.12s/it] 36%|███▌      | 371/1024 [3:59:20<6:11:21, 34.12s/it] 36%|███▋      | 372/1024 [3:59:55<6:10:44, 34.12s/it] 36%|███▋      | 373/1024 [4:00:29<6:10:14, 34.12s/it] 37%|███▋      | 374/1024 [4:01:03<6:09:40, 34.12s/it] 37%|███▋      | 375/1024 [4:01:37<6:09:03, 34.12s/it] 37%|███▋      | 376/1024 [4:02:11<6:08:29, 34.12s/it] 37%|███▋      | 377/1024 [4:02:45<6:07:55, 34.12s/it] 37%|███▋      | 378/1024 [4:03:19<6:07:19, 34.12s/it] 37%|███▋      | 379/1024 [4:03:53<6:06:44, 34.12s/it] 37%|███▋      | 380/1024 [4:04:27<6:06:11, 34.12s/it] 37%|███▋      | 381/1024 [4:05:02<6:05:41, 34.12s/it] 37%|███▋      | 382/1024 [4:05:36<6:05:07, 34.12s/it] 37%|███▋      | 383/1024 [4:06:10<6:04:33, 34.12s/it] 38%|███▊      | 384/1024 [4:06:44<6:03:58, 34.12s/it]                                                      {'loss': 1.3058, 'grad_norm': 0.3223493580255929, 'learning_rate': 0.000276536686473018, 'epoch': 0.79}
 38%|███▊      | 384/1024 [4:06:44<6:03:58, 34.12s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.51s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  9.00s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.70s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.14s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.42s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.61s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.82s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.95s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.97s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.01s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9277452230453491, 'eval_runtime': 242.2945, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.79}
 38%|███▊      | 384/1024 [4:10:46<6:03:58, 34.12s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 38%|███▊      | 385/1024 [4:11:20<18:57:40, 106.82s/it] 38%|███▊      | 386/1024 [4:11:55<15:03:58, 85.01s/it]  38%|███▊      | 387/1024 [4:12:29<12:20:29, 69.75s/it] 38%|███▊      | 388/1024 [4:13:03<10:26:00, 59.06s/it] 38%|███▊      | 389/1024 [4:13:37<9:05:48, 51.57s/it]  38%|███▊      | 390/1024 [4:14:11<8:09:33, 46.33s/it] 38%|███▊      | 391/1024 [4:14:45<7:30:05, 42.66s/it] 38%|███▊      | 392/1024 [4:15:19<7:02:23, 40.10s/it] 38%|███▊      | 393/1024 [4:15:53<6:42:54, 38.31s/it] 38%|███▊      | 394/1024 [4:16:28<6:29:06, 37.06s/it] 39%|███▊      | 395/1024 [4:17:02<6:19:17, 36.18s/it] 39%|███▊      | 396/1024 [4:17:36<6:12:15, 35.57s/it] 39%|███▉      | 397/1024 [4:18:10<6:07:06, 35.13s/it] 39%|███▉      | 398/1024 [4:18:44<6:03:19, 34.82s/it] 39%|███▉      | 399/1024 [4:19:18<6:00:33, 34.61s/it] 39%|███▉      | 400/1024 [4:19:52<5:58:26, 34.47s/it] 39%|███▉      | 401/1024 [4:20:26<5:56:51, 34.37s/it] 39%|███▉      | 402/1024 [4:21:00<5:55:29, 34.29s/it] 39%|███▉      | 403/1024 [4:21:35<5:54:21, 34.24s/it] 39%|███▉      | 404/1024 [4:22:09<5:53:24, 34.20s/it] 40%|███▉      | 405/1024 [4:22:43<5:52:34, 34.18s/it] 40%|███▉      | 406/1024 [4:23:17<5:51:46, 34.15s/it] 40%|███▉      | 407/1024 [4:23:51<5:51:03, 34.14s/it] 40%|███▉      | 408/1024 [4:24:25<5:50:20, 34.12s/it]                                                      {'loss': 1.2928, 'grad_norm': 5.229923866330981, 'learning_rate': 0.00026273634807977834, 'epoch': 0.84}
 40%|███▉      | 408/1024 [4:24:25<5:50:20, 34.12s/it] 40%|███▉      | 409/1024 [4:24:59<5:49:43, 34.12s/it] 40%|████      | 410/1024 [4:25:33<5:49:05, 34.11s/it] 40%|████      | 411/1024 [4:26:07<5:48:31, 34.11s/it] 40%|████      | 412/1024 [4:26:42<5:47:57, 34.11s/it] 40%|████      | 413/1024 [4:27:16<5:47:23, 34.11s/it] 40%|████      | 414/1024 [4:27:50<5:46:53, 34.12s/it] 41%|████      | 415/1024 [4:28:24<5:46:21, 34.12s/it] 41%|████      | 416/1024 [4:28:58<5:45:48, 34.13s/it] 41%|████      | 417/1024 [4:29:32<5:45:15, 34.13s/it] 41%|████      | 418/1024 [4:30:06<5:44:40, 34.13s/it] 41%|████      | 419/1024 [4:30:40<5:44:04, 34.12s/it] 41%|████      | 420/1024 [4:31:15<5:43:28, 34.12s/it] 41%|████      | 421/1024 [4:31:49<5:42:53, 34.12s/it] 41%|████      | 422/1024 [4:32:23<5:42:15, 34.11s/it] 41%|████▏     | 423/1024 [4:32:57<5:41:44, 34.12s/it] 41%|████▏     | 424/1024 [4:33:31<5:41:09, 34.12s/it] 42%|████▏     | 425/1024 [4:34:05<5:40:34, 34.11s/it] 42%|████▏     | 426/1024 [4:34:39<5:40:00, 34.11s/it] 42%|████▏     | 427/1024 [4:35:13<5:39:23, 34.11s/it] 42%|████▏     | 428/1024 [4:35:47<5:38:52, 34.11s/it] 42%|████▏     | 429/1024 [4:36:22<5:38:19, 34.12s/it] 42%|████▏     | 430/1024 [4:36:56<5:37:43, 34.11s/it] 42%|████▏     | 431/1024 [4:37:30<5:37:04, 34.11s/it] 42%|████▏     | 432/1024 [4:38:04<5:36:30, 34.11s/it]                                                      {'loss': 1.2936, 'grad_norm': 0.09133865445196024, 'learning_rate': 0.0002485960359806528, 'epoch': 0.89}
 42%|████▏     | 432/1024 [4:38:04<5:36:30, 34.11s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  8.99s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.69s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.41s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.82s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.88s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.94s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.96s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.97s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 10.99s/it][A
 82%|████████▏ | 18/22 [03:07<00:43, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:21, 11.00s/it][A
 95%|█████████▌| 21/22 [03:40<00:10, 11.00s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A                                                      
                                               [A{'eval_loss': 0.9250954985618591, 'eval_runtime': 242.1703, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.89}
 42%|████▏     | 432/1024 [4:42:06<5:36:30, 34.11s/it]
100%|██████████| 22/22 [03:51<00:00, 11.00s/it][A
                                               [A 42%|████▏     | 433/1024 [4:42:40<17:31:43, 106.77s/it] 42%|████▏     | 434/1024 [4:43:14<13:55:35, 84.98s/it]  42%|████▏     | 435/1024 [4:43:48<11:24:27, 69.72s/it] 43%|████▎     | 436/1024 [4:44:23<9:38:36, 59.04s/it]  43%|████▎     | 437/1024 [4:44:57<8:24:28, 51.57s/it] 43%|████▎     | 438/1024 [4:45:31<7:32:31, 46.33s/it] 43%|████▎     | 439/1024 [4:46:05<6:56:02, 42.67s/it] 43%|████▎     | 440/1024 [4:46:39<6:30:22, 40.11s/it] 43%|████▎     | 441/1024 [4:47:13<6:12:15, 38.31s/it] 43%|████▎     | 442/1024 [4:47:47<5:59:25, 37.05s/it] 43%|████▎     | 443/1024 [4:48:21<5:50:17, 36.17s/it] 43%|████▎     | 444/1024 [4:48:56<5:43:39, 35.55s/it] 43%|████▎     | 445/1024 [4:49:30<5:38:54, 35.12s/it] 44%|████▎     | 446/1024 [4:50:04<5:35:22, 34.81s/it] 44%|████▎     | 447/1024 [4:50:38<5:32:43, 34.60s/it] 44%|████▍     | 448/1024 [4:51:12<5:30:41, 34.45s/it] 44%|████▍     | 449/1024 [4:51:46<5:29:06, 34.34s/it] 44%|████▍     | 450/1024 [4:52:20<5:27:51, 34.27s/it] 44%|████▍     | 451/1024 [4:52:54<5:26:47, 34.22s/it] 44%|████▍     | 452/1024 [4:53:28<5:25:51, 34.18s/it] 44%|████▍     | 453/1024 [4:54:02<5:25:02, 34.16s/it] 44%|████▍     | 454/1024 [4:54:37<5:24:23, 34.15s/it] 44%|████▍     | 455/1024 [4:55:11<5:23:46, 34.14s/it] 45%|████▍     | 456/1024 [4:55:45<5:23:08, 34.13s/it]                                                      {'loss': 1.2705, 'grad_norm': 0.10137931370682679, 'learning_rate': 0.00023419237775206027, 'epoch': 0.93}
 45%|████▍     | 456/1024 [4:55:45<5:23:08, 34.13s/it] 45%|████▍     | 457/1024 [4:56:19<5:22:34, 34.13s/it] 45%|████▍     | 458/1024 [4:56:53<5:21:56, 34.13s/it] 45%|████▍     | 459/1024 [4:57:27<5:21:23, 34.13s/it] 45%|████▍     | 460/1024 [4:58:01<5:20:45, 34.12s/it] 45%|████▌     | 461/1024 [4:58:35<5:20:07, 34.12s/it] 45%|████▌     | 462/1024 [4:59:10<5:19:32, 34.11s/it] 45%|████▌     | 463/1024 [4:59:44<5:19:01, 34.12s/it] 45%|████▌     | 464/1024 [5:00:18<5:18:26, 34.12s/it] 45%|████▌     | 465/1024 [5:00:52<5:17:56, 34.13s/it] 46%|████▌     | 466/1024 [5:01:26<5:17:21, 34.12s/it] 46%|████▌     | 467/1024 [5:02:00<5:16:45, 34.12s/it] 46%|████▌     | 468/1024 [5:02:34<5:16:11, 34.12s/it] 46%|████▌     | 469/1024 [5:03:08<5:15:39, 34.12s/it] 46%|████▌     | 470/1024 [5:03:42<5:15:01, 34.12s/it] 46%|████▌     | 471/1024 [5:04:17<5:14:25, 34.12s/it] 46%|████▌     | 472/1024 [5:04:51<5:13:49, 34.11s/it] 46%|████▌     | 473/1024 [5:05:25<5:13:14, 34.11s/it] 46%|████▋     | 474/1024 [5:05:59<5:12:41, 34.11s/it] 46%|████▋     | 475/1024 [5:06:33<5:12:04, 34.11s/it] 46%|████▋     | 476/1024 [5:07:07<5:11:27, 34.10s/it] 47%|████▋     | 477/1024 [5:07:41<5:10:53, 34.10s/it] 47%|████▋     | 478/1024 [5:08:15<5:10:20, 34.10s/it] 47%|████▋     | 479/1024 [5:08:49<5:09:48, 34.11s/it] 47%|████▋     | 480/1024 [5:09:24<5:09:14, 34.11s/it]                                                      {'loss': 1.2951, 'grad_norm': 0.3153597790393129, 'learning_rate': 0.0002196034280659122, 'epoch': 0.98}
 47%|████▋     | 480/1024 [5:09:24<5:09:14, 34.11s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:11<01:50,  5.50s/it][A
 14%|█▎        | 3/22 [00:22<02:28,  7.80s/it][A
 18%|█▊        | 4/22 [00:33<02:41,  9.00s/it][A
 23%|██▎       | 5/22 [00:44<02:44,  9.70s/it][A
 27%|██▋       | 6/22 [00:55<02:42, 10.13s/it][A
 32%|███▏      | 7/22 [01:06<02:36, 10.42s/it][A
 36%|███▋      | 8/22 [01:17<02:28, 10.60s/it][A
 41%|████      | 9/22 [01:28<02:19, 10.73s/it][A
 45%|████▌     | 10/22 [01:39<02:09, 10.81s/it][A
 50%|█████     | 11/22 [01:50<01:59, 10.87s/it][A
 55%|█████▍    | 12/22 [02:01<01:49, 10.92s/it][A
 59%|█████▉    | 13/22 [02:12<01:38, 10.94s/it][A
 64%|██████▎   | 14/22 [02:23<01:27, 10.96s/it][A
 68%|██████▊   | 15/22 [02:34<01:16, 10.98s/it][A
 73%|███████▎  | 16/22 [02:45<01:05, 10.99s/it][A
 77%|███████▋  | 17/22 [02:56<00:54, 11.00s/it][A
 82%|████████▏ | 18/22 [03:07<00:44, 11.00s/it][A
 86%|████████▋ | 19/22 [03:18<00:33, 11.00s/it][A
 91%|█████████ | 20/22 [03:29<00:22, 11.01s/it][A
 95%|█████████▌| 21/22 [03:40<00:11, 11.01s/it][A
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A                                                      
                                               [A{'eval_loss': 0.9214087724685669, 'eval_runtime': 242.2458, 'eval_samples_per_second': 0.714, 'eval_steps_per_second': 0.091, 'epoch': 0.98}
 47%|████▋     | 480/1024 [5:13:26<5:09:14, 34.11s/it]
100%|██████████| 22/22 [03:51<00:00, 11.01s/it][A
                                               [A 47%|████▋     | 481/1024 [5:14:00<16:06:33, 106.80s/it] 47%|████▋     | 482/1024 [5:14:34<12:47:50, 85.00s/it]  47%|████▋     | 483/1024 [5:15:08<10:28:50, 69.74s/it] 47%|████▋     | 484/1024 [5:15:42<8:51:31, 59.06s/it]  47%|████▋     | 485/1024 [5:16:16<7:43:19, 51.58s/it] 47%|████▋     | 486/1024 [5:16:51<6:55:30, 46.34s/it] 48%|████▊     | 487/1024 [5:17:25<6:21:53, 42.67s/it] 48%|████▊     | 488/1024 [5:17:59<5:58:17, 40.11s/it] 48%|████▊     | 489/1024 [5:18:33<5:41:37, 38.31s/it] 48%|████▊     | 490/1024 [5:19:07<5:29:46, 37.05s/it] 48%|████▊     | 491/1024 [5:19:41<5:21:25, 36.18s/it] 48%|████▊     | 492/1024 [5:20:15<5:15:19, 35.56s/it] 48%|████▊     | 493/1024 [5:20:49<5:10:53, 35.13s/it]srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 193713.0 ON compute14 CANCELLED AT 2024-03-19T23:46:55 ***
