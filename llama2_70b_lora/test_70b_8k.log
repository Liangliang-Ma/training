[2024-02-28 20:48:16,054] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
could not open any host key
ssh_keysign: no reply
sign using hostkey ssh-ed25519 SHA256:9AX4dFSSpcAMAJhyYK5BBAhA6FO0voQ4qjlON/fIicA failed
[2024-02-28 20:48:17,595] [INFO] [runner.py:463:main] Using IP address of 172.16.1.34 for node compute34
[2024-02-28 20:48:17,597] [INFO] [runner.py:568:main] cmd = mpirun -n 8 -ppn 8 -hostfile hostfile_mpich -genv PYTHONSTARTUP=/etc/pythonstart -genv PYTHONPATH=/home/maliangl/ft/reference/llama2_70b_lora -genv MASTER_ADDR 172.16.1.34 -genv MASTER_PORT 29500 -genv WORLD_SIZE 8 -genv LOCAL_SIZE 8 -hosts compute34 /home/maliangl/miniconda3/envs/ft/bin/python -u /home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/launcher/launcher_helper.py --launcher mpich scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
My guessed rank = 5
My guessed rank = 4
My guessed rank = 6
My guessed rank = 7
My guessed rank = 0
My guessed rank = 1
My guessed rank = 2
My guessed rank = 3
[2024-02-28 20:48:21,765] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,033] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,047] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,056] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,060] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,062] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,064] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,072] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,073] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:22,306] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,313] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,317] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,318] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,323] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,329] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
[2024-02-28 20:48:22,331] [INFO] [launcher_helper.py:101:main] launcher_helper cmd = /home/maliangl/miniconda3/envs/ft/bin/python -u scripts/train.py --model_path /scratch/users/maliangl/Llama-2-70b-hf --dataset_name tau/scrolls --dataset_config_name gov_report --max_seq_len 8192 --bf16 True --logging_steps 2 --eval_steps 6 --save_steps 999 --output_dir ./results/llama-70b_scrolls_gov_report_r16_666 --per_device_train_batch_size 1 --gradient_accumulation_steps 1 --lr_scheduler_type cosine --learning_rate 5e-4 --warmup_ratio 0 --use_gradient_checkpointing True --target_eval_loss 0.925 --use_peft_lora True --lora_r 16 --lora_alpha 16 --lora_dropout 0.1 --max_steps 800 --seed 666 --lora_target_modules qkv_proj,o_proj
My guessed rank = 3
My guessed rank = 0
My guessed rank = 1
My guessed rank = 2
My guessed rank = 5
My guessed rank = 4
My guessed rank = 6
My guessed rank = 7
[2024-02-28 20:48:27,338] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,420] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,437] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,438] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,441] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,446] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,447] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,471] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to xpu (auto detect)
[2024-02-28 20:48:27,663] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:27,663] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,102] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,102] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,120] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,120] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,120] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend ccl
[2024-02-28 20:48:28,150] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,150] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,150] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,150] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,153] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,153] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,154] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,154] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:28,154] [INFO] [comm.py:161:init_deepspeed_backend] Initialize ccl backend
[2024-02-28 20:48:28,154] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-02-28 20:48:36,501] [INFO] [partition_parameters.py:343:__exit__] finished initializing model - num_params = 723, num_elems = 68.98B
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.97s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.97s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.97s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.98s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.98s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.98s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 11.98s/it]Loading checkpoint shards:   7%|▋         | 1/15 [00:11<02:47, 12.00s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.79s/it]Loading checkpoint shards:  13%|█▎        | 2/15 [00:21<02:20, 10.80s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:06, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.58s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.59s/it]Loading checkpoint shards:  20%|██        | 3/15 [00:32<02:07, 10.59s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.05s/it]Loading checkpoint shards:  27%|██▋       | 4/15 [00:44<02:01, 11.04s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:54<01:50, 11.01s/it]Loading checkpoint shards:  33%|███▎      | 5/15 [00:55<01:50, 11.02s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.74s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.74s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.74s/it]Loading checkpoint shards:  40%|████      | 6/15 [01:05<01:36, 10.73s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.52s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.52s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.52s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.53s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.53s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.53s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.53s/it]Loading checkpoint shards:  47%|████▋     | 7/15 [01:15<01:24, 10.53s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.37s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.37s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.38s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.37s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.38s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.38s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.38s/it]Loading checkpoint shards:  53%|█████▎    | 8/15 [01:25<01:12, 10.37s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.47s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.48s/it]Loading checkpoint shards:  60%|██████    | 9/15 [01:36<01:02, 10.48s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.70s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.70s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.70s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.71s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.71s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.71s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.70s/it]Loading checkpoint shards:  67%|██████▋   | 10/15 [01:47<00:53, 10.71s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:59<00:45, 11.33s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:59<00:45, 11.33s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:59<00:45, 11.33s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:59<00:45, 11.33s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [01:59<00:45, 11.33s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [02:00<00:45, 11.34s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [02:00<00:45, 11.34s/it]Loading checkpoint shards:  73%|███████▎  | 11/15 [02:00<00:45, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  80%|████████  | 12/15 [02:11<00:34, 11.34s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  87%|████████▋ | 13/15 [02:22<00:22, 11.29s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards:  93%|█████████▎| 14/15 [02:33<00:11, 11.24s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.04s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00,  8.05s/it]Loading checkpoint shards: 100%|██████████| 15/15 [02:34<00:00, 10.29s/it]
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:2508: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=<use_auth_token>' instead.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/datasets/load.py:1454: FutureWarning: The repository for tau/scrolls contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tau/scrolls
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:33, 32.08 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:33, 32.03 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:33, 32.02 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:35, 31.92 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 77.23 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:35, 31.91 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:36, 31.85 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 77.09 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:31<08:36, 31.88 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:20, 76.95 examples/s]Map (num_proc=8):  11%|█▏        | 2000/17457 [00:31<03:21, 76.66 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:02, 118.03 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:47, 134.95 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:47, 134.18 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:02, 117.74 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:01, 220.28 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:15, 178.00 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:02, 216.79 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:15, 178.23 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<02:03, 117.19 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:48, 132.89 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:32<01:49, 132.05 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:37, 333.73 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:01, 217.18 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:41, 298.65 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:32<01:16, 175.77 examples/s]Map (num_proc=8):  29%|██▊       | 5000/17457 [00:32<00:48, 259.17 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:35, 323.96 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:26, 438.37 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:29, 385.14 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:28, 406.61 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:35, 322.72 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:28, 408.62 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:33<00:33, 337.69 examples/s]Map (num_proc=8):   6%|▌         | 1000/17457 [00:34<09:21, 29.32 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:17, 581.12 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:19, 535.55 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:20, 500.34 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:25, 407.41 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:20, 514.89 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:34<00:25, 411.84 examples/s]Map (num_proc=8):  17%|█▋        | 3000/17457 [00:35<02:13, 108.69 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:20, 467.59 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:16, 568.04 examples/s]Map (num_proc=8):  23%|██▎       | 4000/17457 [00:35<01:22, 162.15 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:17, 548.50 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:20, 464.38 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:15, 602.69 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:16, 559.17 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:35<00:18, 505.72 examples/s]Map (num_proc=8):  34%|███▍      | 6000/17457 [00:36<00:37, 307.15 examples/s]Map (num_proc=8):  40%|████      | 7000/17457 [00:36<00:27, 386.34 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:38<00:22, 420.26 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:15, 602.69 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:17, 548.50 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:16, 559.17 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:18, 505.72 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:20, 467.59 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:22, 420.26 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:16, 568.04 examples/s]Map (num_proc=8):  46%|████▌     | 8000/17457 [00:52<00:20, 464.38 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:19, 105.96 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:17, 108.62 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:09, 121.04 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:49, 150.54 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:49, 152.16 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:16, 110.99 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:45, 163.99 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:02<00:48, 154.97 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:02<01:18, 108.41 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:49, 151.05 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:17, 108.88 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:03<01:18, 107.68 examples/s]Map (num_proc=8):  57%|█████▋    | 10000/17457 [01:03<00:49, 150.69 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:33, 193.95 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:32, 200.99 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:04<00:34, 187.98 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:33, 191.67 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:33, 193.03 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:34, 187.38 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:05<00:36, 177.21 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:25, 213.81 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:07<00:25, 215.95 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:25, 218.16 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:24, 219.53 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:08<00:08, 391.16 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:24, 218.38 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:25, 211.20 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:08<00:14, 302.34 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:08<00:27, 197.12 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:08<00:08, 422.58 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:08<00:09, 378.80 examples/s]Map (num_proc=8):  76%|███████▌  | 13183/17457 [01:08<00:13, 309.05 examples/s]Map (num_proc=8):  81%|████████  | 14183/17457 [01:08<00:08, 385.37 examples/s]Map (num_proc=8):  81%|████████  | 14183/17457 [01:08<00:08, 396.33 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:08<00:10, 328.63 examples/s]Map (num_proc=8):  82%|████████▏ | 14365/17457 [01:08<00:06, 446.26 examples/s]Map (num_proc=8):  82%|████████▏ | 14365/17457 [01:08<00:07, 402.81 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:08<00:03, 604.45 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:04, 516.57 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:03, 528.41 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:03, 559.28 examples/s]Map (num_proc=8):  52%|█████▏    | 9000/17457 [01:09<01:26, 97.54 examples/s] Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:04, 512.29 examples/s]Map (num_proc=8):  87%|████████▋ | 15183/17457 [01:09<00:03, 575.31 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:09<00:04, 438.42 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 685.52 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:09<00:01, 591.98 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 584.66 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 641.66 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:02, 493.03 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 560.25 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:10<00:01, 653.16 examples/s]Map (num_proc=8):  63%|██████▎   | 11000/17457 [01:11<00:40, 161.30 examples/s]Map (num_proc=8):  69%|██████▊   | 12000/17457 [01:13<00:27, 195.89 examples/s]Map (num_proc=8):  74%|███████▍  | 13000/17457 [01:13<00:17, 257.22 examples/s]Map (num_proc=8):  80%|████████  | 14000/17457 [01:13<00:10, 336.56 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 362.00 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 354.07 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 345.30 examples/s]Map (num_proc=8):  86%|████████▌ | 15000/17457 [01:14<00:05, 436.57 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 360.27 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:01, 374.52 examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:14<00:02, 332.94 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 350.06 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 343.34 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:14<00:01, 350.85 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 375.54 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 367.14 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:01, 353.47 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:15<00:01, 363.15 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 405.77 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 413.64 examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:15<00:01, 339.77 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:00, 385.27 examples/s]Map (num_proc=8):  88%|████████▊ | 15365/17457 [01:15<00:04, 424.01 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:15<00:01, 343.03 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 378.19 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 416.00 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 414.04 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 369.70 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:15<00:00, 357.43 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:15<00:00, 398.97 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 361.78 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 382.05 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:16<00:00, 379.83 examples/s]Map (num_proc=8):  94%|█████████▎| 16365/17457 [01:16<00:02, 529.74 examples/s]Map (num_proc=8):  95%|█████████▍| 16547/17457 [01:17<00:02, 432.85 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:17<00:00, 224.12 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:17<00:00, 223.99 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:17<00:00, 224.11 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:18<00:00, 223.49 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:18<00:00, 223.73 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:18<00:00, 223.59 examples/s]
Map (num_proc=8): 100%|██████████| 17457/17457 [01:18<00:00, 223.23 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8):  96%|█████████▌| 16729/17457 [01:19<00:02, 328.67 examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=8):  97%|█████████▋| 16911/17457 [01:19<00:01, 327.77 examples/s]Map (num_proc=8):  98%|█████████▊| 17093/17457 [01:20<00:01, 326.10 examples/s]Map (num_proc=8):  99%|█████████▉| 17275/17457 [01:20<00:00, 358.57 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:22<00:00, 272.59 examples/s]Map (num_proc=8): 100%|██████████| 17457/17457 [01:22<00:00, 211.79 examples/s]
Map (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.16 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.30 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.10 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.22 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:29<00:29, 16.21 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.17 examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:31<00:31, 15.67 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:30<00:00, 37.60 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.04 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 36.91 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.40 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.93 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.25 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.47 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.16 examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:32<00:00, 30.09 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.64 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:32<00:00, 30.24 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.58 examples/s]
Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.54 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.45 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 486/972 [00:30<00:30, 16.14 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 37.51 examples/s]Map (num_proc=2): 100%|██████████| 972/972 [00:31<00:00, 30.98 examples/s]
Filter (num_proc=8):   0%|          | 0/17457 [00:00<?, ? examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:55, 298.40 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1501.77 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 301.91 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3430.77 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 300.87 examples/s]Filter (num_proc=8):  17%|█▋        | 3000/17457 [00:03<00:13, 1101.40 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 300.32 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:55, 297.21 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1503.84 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 299.49 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1930.32 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:04, 2651.72 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:54, 301.93 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:03<00:03, 3066.06 examples/s]Filter (num_proc=8):  29%|██▊       | 5000/17457 [00:03<00:06, 1909.53 examples/s]Filter (num_proc=8):  40%|████      | 7000/17457 [00:03<00:04, 2607.58 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3406.93 examples/s]Filter (num_proc=8):  23%|██▎       | 4000/17457 [00:03<00:08, 1514.76 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3414.00 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3595.88 examples/s]Filter (num_proc=8):  46%|████▌     | 8000/17457 [00:03<00:02, 3589.39 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1561.47 examples/s]Filter (num_proc=8):   6%|▌         | 1000/17457 [00:03<00:55, 297.40 examples/s]Filter (num_proc=8):  34%|███▍      | 6000/17457 [00:03<00:05, 2289.79 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1520.07 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2031.51 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:06, 1403.73 examples/s]Filter (num_proc=8):  57%|█████▋    | 10000/17457 [00:06<00:04, 1592.06 examples/s]Filter (num_proc=8):  86%|████████▌ | 15000/17457 [00:06<00:00, 3161.72 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1729.11 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1904.10 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2110.35 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1651.59 examples/s]Filter (num_proc=8):  69%|██████▊   | 12000/17457 [00:06<00:02, 2109.68 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1666.85 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1721.59 examples/s]Filter (num_proc=8):  86%|████████▌ | 15000/17457 [00:06<00:00, 3267.55 examples/s]Filter (num_proc=8):  87%|████████▋ | 15183/17457 [00:07<00:00, 3925.57 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3093.43 examples/s]Filter (num_proc=8):  95%|█████████▍| 16547/17457 [00:07<00:00, 3273.60 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3081.96 examples/s]Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 2578.90 examples/s]Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:07<00:00, 3468.80 examples/s]Filter (num_proc=8):  93%|█████████▎| 16183/17457 [00:07<00:00, 3294.38 examples/s]Filter (num_proc=8):  95%|█████████▍| 16547/17457 [00:07<00:00, 3439.32 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2251.42 examples/s]
Filter (num_proc=8):  96%|█████████▌| 16729/17457 [00:07<00:00, 3744.40 examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2310.53 examples/s]
Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 3278.69 examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2311.13 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2263.10 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2315.28 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2222.14 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2230.41 examples/s]
Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=2):   0%|          | 0/972 [00:00<?, ? examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 282.26 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 628.10 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 509.78 examples/s]
Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 286.46 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 284.42 examples/s]Filter (num_proc=8):  52%|█████▏    | 9000/17457 [00:06<00:05, 1447.22 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 286.06 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 624.87 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 289.26 examples/s]Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 283.26 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 509.67 examples/s]
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 624.79 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 518.48 examples/s]
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 644.73 examples/s]Filter (num_proc=8):  63%|██████▎   | 11000/17457 [00:06<00:03, 1945.54 examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2):  50%|█████     | 486/972 [00:01<00:01, 278.36 examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 509.95 examples/s]
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 522.91 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 521.57 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=8):  80%|████████  | 14000/17457 [00:06<00:01, 2996.59 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=2): 100%|██████████| 972/972 [00:01<00:00, 515.23 examples/s]
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Before packing, Size of the train set: 5604. Size of the validation set: 243
Filter (num_proc=8):  92%|█████████▏| 16000/17457 [00:06<00:00, 3859.96 examples/s]Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Filter (num_proc=8): 100%|██████████| 17457/17457 [00:07<00:00, 2288.97 examples/s]
Before packing, Size of the train set: 5604. Size of the validation set: 243
Map (num_proc=8):   0%|          | 0/5604 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 441.51 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2053.41 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 440.62 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 438.62 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3130.28 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 436.66 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 441.37 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:01<00:00, 4431.27 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 2017.28 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 416.43 examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:01<00:11, 437.57 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:01<00:02, 1382.57 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 1974.38 examples/s]Map (num_proc=8):  25%|██▌       | 1402/5604 [00:01<00:04, 916.52 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3033.53 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:01<00:02, 1419.93 examples/s]Map (num_proc=8):  63%|██████▎   | 3503/5604 [00:01<00:00, 2566.50 examples/s]Map (num_proc=8):  38%|███▊      | 2103/5604 [00:01<00:02, 1517.25 examples/s]Map (num_proc=8):  50%|█████     | 2804/5604 [00:01<00:01, 1929.94 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 4652.00 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:02<00:00, 2212.07 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:02<00:00, 2957.23 examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:02<00:00, 2397.62 examples/s]Map (num_proc=8):  75%|███████▌  | 4204/5604 [00:01<00:00, 3058.47 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3572.93 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3593.27 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3856.16 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 3223.02 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:02<00:00, 2741.69 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 984.42 examples/s] 
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 988.74 examples/s] 
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 1024.61 examples/s]
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 1000.26 examples/s]
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 984.51 examples/s] 
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 970.56 examples/s] 
Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 990.48 examples/s] 
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8):  13%|█▎        | 701/5604 [00:04<00:34, 142.18 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8):  63%|██████▎   | 3504/5604 [00:05<00:02, 917.03 examples/s]Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 1609.19 examples/s]Map (num_proc=8): 100%|██████████| 5604/5604 [00:05<00:00, 961.03 examples/s] 
Map (num_proc=2):   0%|          | 0/243 [00:00<?, ? examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:01<00:01, 112.90 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:01<00:01, 101.66 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:01<00:01, 93.60 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 135.00 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 140.48 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:01<00:01, 104.91 examples/s]Map (num_proc=2):  50%|█████     | 122/243 [00:01<00:01, 104.49 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 216.57 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 221.19 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 199.97 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 271.75 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 211.84 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 249.44 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 210.63 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 162.46 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 140.28 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2):  50%|█████     | 122/243 [00:00<00:00, 231.68 examples/s]Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 140.78 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 148.02 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 138.00 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 170.08 examples/s]
Map (num_proc=2): 100%|██████████| 243/243 [00:01<00:00, 165.98 examples/s]
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 8192, padding_idx=0)
        (layers): ModuleList(
          (0-79): 80 x LlamaDecoderLayer(
            (self_attn): LlamaAttention(
              (q_proj): Linear(in_features=8192, out_features=8192, bias=False)
              (k_proj): Linear(in_features=8192, out_features=1024, bias=False)
              (v_proj): Linear(in_features=8192, out_features=1024, bias=False)
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=8192, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=8192, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
    )
  )
)
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
prepare all done!
prepare all done!
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Map (num_proc=2): 100%|██████████| 243/243 [00:00<00:00, 371.38 examples/s]
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
Size of the train set: 3901. Size of the validation set: 173
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
prepare all done!
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
trainable params: 20,971,520 || all params: 68,997,619,712 || trainable%: 0.03039455576516454
prepare all done!
prepare all done!
prepare all done!
prepare all done!
prepare all done!
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
mll zero 3
Parameter Offload: Total persistent parameters: 1318912 in 161 params
:::MLLOG {"namespace": "", "time_ms": 1709182404209, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 92}}
:::MLLOG {"namespace": "", "time_ms": 1709182404210, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "Closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 96}}
:::MLLOG {"namespace": "", "time_ms": 1709182404210, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 100}}
:::MLLOG {"namespace": "", "time_ms": 1709182404210, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 103}}
:::MLLOG {"namespace": "", "time_ms": 1709182404210, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 107}}
:::MLLOG {"namespace": "", "time_ms": 1709182404210, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 111}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": "8", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 119}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 125}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 129}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "seed", "value": 666, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 133}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 134}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 800, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 135}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0005, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 138}}
:::MLLOG {"namespace": "", "time_ms": 1709182404211, "event_type": "INTERVAL_START", "key": "run_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 139}}
  0%|          | 0/800 [00:00<?, ?it/s]/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
Traceback (most recent call last):
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 222, in <module>
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    main(args)
  File "/home/maliangl/ft/reference/llama2_70b_lora/scripts/train.py", line 216, in main
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    trainer.train()
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    return inner_training_loop(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 1961, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    tr_loss_step = self.training_step(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2902, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    loss = self.compute_loss(model, inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/trainer.py", line 2925, in compute_loss
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = model(**inputs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    return forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/utils/nvtx.py", line 15, in wrapped_fn
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    ret_val = func(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/deepspeed/runtime/engine.py", line 1852, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    loss = self.module(*inputs, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/peft_model.py", line 1083, in forward
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self.base_model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/peft/tuners/tuners_utils.py", line 161, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    return self.model.forward(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 1168, in forward
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = self.model(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 997, in forward
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    layer_outputs = self._gradient_checkpointing_func(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_compile.py", line 24, in inner
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 328, in _fn
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/_dynamo/external_utils.py", line 17, in inner
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return fn(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 451, in checkpoint
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return CheckpointFunction.apply(function, preserve, *args)
    return CheckpointFunction.apply(function, preserve, *args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/autograd/function.py", line 539, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/utils/checkpoint.py", line 230, in forward
    outputs = run_function(*args)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 734, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1568, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    result = forward_call(*args, **kwargs)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py", line 375, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/maliangl/miniconda3/envs/ft/lib/python3.9/site-packages/torch/nn/functional.py", line 1858, in softmax
    ret = input.softmax(dim, dtype=dtype)
RuntimeError    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
    ret = input.softmax(dim, dtype=dtype)
RuntimeError: Allocation is out of device memory on current platform.
  0%|          | 0/800 [00:41<?, ?it/s]

===================================================================================
=   BAD TERMINATION OF ONE OF YOUR APPLICATION PROCESSES
=   RANK 4 PID 39432 RUNNING AT compute34
=   KILLED BY SIGNAL: 9 (Killed)
===================================================================================
